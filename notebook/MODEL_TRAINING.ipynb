{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b9025c",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac0ca5",
   "metadata": {},
   "source": [
    "## 1.1 Import data and required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9929071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, roc_auc_score,accuracy_score)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d538b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data\\cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f2e455f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 74)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89be695",
   "metadata": {},
   "source": [
    "# Spliting data into traing and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced85510",
   "metadata": {},
   "source": [
    "Preparing X and y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d274d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('TARGET', axis=1)\n",
    "y = df['TARGET']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y     # used because it will divide classes equally for training and testing datasets mean total 92 def and 8 non def \n",
    "                    # train will also contain same ratio as testing       \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a4c31",
   "metadata": {},
   "source": [
    "### identifying numeric features ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6c3e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "num = X_train.select_dtypes(include=['int64', 'float64'])\n",
    "cat = X_train.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff8d680",
   "metadata": {},
   "source": [
    "# Data Scaling and Imputing with encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d328236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230633, 190)\n",
      "(76878, 190)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine both\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, num_cols),\n",
    "        ('cat', cat_pipeline, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit & transform\n",
    "X_train_final = preprocessor.fit_transform(X_train)\n",
    "X_test_final  = preprocessor.transform(X_test)\n",
    "\n",
    "print(X_train_final.shape)\n",
    "print(X_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1051c",
   "metadata": {},
   "source": [
    "# Creating an evaluation function to check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd5e88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test_final, y_test ):\n",
    "    y_pred=model.predict(X_test_final)\n",
    "    y_proba = model.predict_proba(X_test_final)[:, 1]\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"ROc:AUC :\",roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd9a559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ec427a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ROC-AUC: 0.7479758564363757 Recall: 0.012568482114083145\n",
      "Decision Tree ROC-AUC: 0.5419010463046308 Recall: 0.16935223976796648\n",
      "Random Forest ROC-AUC: 0.714851214538123 Recall: 0.0016113438607798904\n",
      "Gradient Boosting ROC-AUC: 0.7537112255107289 Recall: 0.012568482114083145\n",
      "AdaBoost ROC-AUC: 0.7419987641226062 Recall: 0.006123106670963584\n",
      "XGBoost ROC-AUC: 0.7476064628331884 Recall: 0.03931679020302933\n",
      "[LightGBM] [Info] Number of positive: 18619, number of negative: 212014\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8667\n",
      "[LightGBM] [Info] Number of data points in the train set: 230633, number of used features: 184\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432470\n",
      "[LightGBM] [Info] Start training from score -2.432470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "e:\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM ROC-AUC: 0.7571774433966676 Recall: 0.019336126329358685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, recall_score\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_final, y_train)\n",
    "    prob = model.predict_proba(X_test_final)[:,1]\n",
    "    y_pred=model.predict(X_test_final)\n",
    "    pred = (prob > 0.5).astype(int)\n",
    "\n",
    "    print(\n",
    "        name,\n",
    "        \"ROC-AUC:\", roc_auc_score(y_test, prob),\n",
    "        \"Recall:\", recall_score(y_test, pred)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b06b6",
   "metadata": {},
   "source": [
    "Structural reasons LightGBM often wins on credit data\n",
    "ðŸ”¹ LightGBM\n",
    "\n",
    "Histogram-based splits\n",
    "\n",
    "Leaf-wise tree growth\n",
    "\n",
    "Handles sparse / one-hot data extremely well\n",
    "\n",
    "Fast and memory-efficient\n",
    "\n",
    "Designed for tabular + imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1cba11",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "LightGBM has higher ROC-AUC\n",
    "\n",
    "XGBoost has slightly higher recall at threshold = 0.5\n",
    "\n",
    "But recall at 0.5 is not meaningful for imbalanced data.\n",
    "ROC-AUC is.\n",
    "\n",
    " Ranking ability > default-threshold recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1c580",
   "metadata": {},
   "source": [
    "# XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "582b0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Calculate scale_pos_weight for your imbalance\n",
    "# ratio = number_of_negative_samples / number_of_positive_samples\n",
    "scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,  # DIRECTLY HANDLES IMBALANCE\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='aucpr'  # Use PR-AUC for imbalanced data\n",
    ")\n",
    "\n",
    "# Tuning these parameters\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'gamma': uniform(0, 1),  # Minimum loss reduction for split\n",
    "    'reg_alpha': uniform(0, 1),  # L1 regularization\n",
    "    'reg_lambda': uniform(1, 2)  # L2 regularization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce45c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8616416574671995\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV( estimator=xgb, param_distributions=param_dist, n_iter=30, \n",
    "  verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train_final, y_train)\n",
    "best_xgb = random_search.best_estimator_\n",
    "print(random_search.best_params_)\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2acee845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92     70672\n",
      "           1       0.22      0.32      0.26      6206\n",
      "\n",
      "    accuracy                           0.85     76878\n",
      "   macro avg       0.58      0.61      0.59     76878\n",
      "weighted avg       0.88      0.85      0.87     76878\n",
      "\n",
      "ROc:AUC : 0.7093270812620007\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_xgb.predict(X_test_final)\n",
    "\n",
    "# Probabilities (this is what actually matters)\n",
    "y_test_prob = best_xgb.predict_proba(X_test_final)[:, 1]\n",
    "evaluate_model(best_xgb, X_test_final,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bc55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe57fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50958cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
